# -*- coding: utf-8 -*-
"""SteakDonenessClassification V1.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10Ou7pwsSA-b71ho2SntqZy840U7j4qCJ

# Introduction

Have you ever eaten steak before? Steak is one of the world's most popular dishes. Originiating from France, steak is meat that has been seared. Steaks can be cooked in different temperatures, ranging from rare steak to well-done steak. Some people have difficulty classifying the doneness of the steak, so this AI will help you determine the cook on your steak in the form of an image.

# Our steak doneness data labels.
"""

from google.colab import files
files.upload()

! pip install kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets download steak-doneness

!unzip steak-doneness.zip -d data

"""# Extracting steak data from Food101 dataset."""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import matplotlib.image as img
# %matplotlib inline
import numpy as np
from collections import defaultdict
import collections
from shutil import copy
from shutil import copytree, rmtree
import tensorflow.keras.backend as K
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
import os
import random
import tensorflow as tf
import tensorflow.keras.backend as K
from tensorflow.keras import regularizers
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.regularizers import l2
from tensorflow import keras
from tensorflow.keras import models
import cv2

print(tf.__version__)
print(tf.test.gpu_device_name())

def get_data_extract():
  if "food-101" in os.listdir():
    print("Dataset already exists")
  else:
    print("Downloading the data...")
    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz
    print("Dataset downloaded!")
    print("Extracting data..")
    !tar xzvf food-101.tar.gz
    print("Extraction done!")

get_data_extract()

!ls food-101/

!kaggle kernels output theimgclist/multiclass-food-classification-using-tensorflow -p /path/to/dest

!zip -r /content/food-101/images/steak.zip /content/food-101/images/steak
files.download('/content/food-101/images/steak.zip')

"""# Training steak data."""

#pytorch ignite
!pip install -q --pre pytorch-ignite 

#fastai
!pip install -q fastbook 

#autogluon
!pip install --upgrade -q mxnet
!pip install -q autogluon

#huggingface and thai2transformers
!pip install -q --upgrade transformers datasets tokenizers #huggingface
!pip install -q emoji pythainlp sklearn-pycrfsuite seqeval #thai2transformers
!rm -r thai2transformers thai2transformers_parent #ลบ folder ที่ download มากรณีรัน cell นี้ซ้ำ
!git clone -b dev https://github.com/vistec-AI/thai2transformers/
!mv thai2transformers thai2transformers_parent
!mv thai2transformers_parent/thai2transformers .

exit()

from google.colab import files
files.upload()

!head steak-train.txt

!head steak-test.txt

!pip install -q fastbook 
from fastbook import *

fields = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    get_items=get_image_files,
    get_y=parent_label,
    splitter=RandomSplitter(valid_pct=0.2, seed=42), # GrandparentSplitter(valid_name='validation')
    item_tfms=RandomResizedCrop(224, min_scale=0.5),
    batch_tfms=aug_transforms()
)

get_image_files("data")

#get_image_files("food-101/images/steak")

parent_label("data/test/000621fb3cbb32d8935728e48679680e.jpg")

#dls = fields.dataloaders("food-101/images/steak")
dls = fields.dataloaders('data')

dls.vocab

dls.train.show_batch(max_n=10, nrows=2)

learner = vision_learner(dls, resnet34, metrics=[error_rate, accuracy])

learner.lr_find()

learner.fine_tune(epochs=15, freeze_epochs=3, base_lr=0.0014454397605732083)

interp = ClassificationInterpretation.from_learner(learner)
interp.plot_confusion_matrix(figsize=(12,12), dpi=60)

interp.most_confused(min_val=5)

learner.show_results(shuffle=True)

"""# Final Notes"""